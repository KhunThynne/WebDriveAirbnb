# -*- coding: utf-8 -*-
"""AirBnb-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11AmGE5YWmsMP0T0leULLWsBOOnZ71O0q

1. ชื่อที่พัก
2. ประเภทที่พัก
3. รายละเอียดที่พัก
4. ราคาต่อคืน
5. คะแนนที่ได้
6. จำนวนรีวิว
7. รีวิวล่าสุด 10-20 รีวิว
8. กราฟ แบ่งตามประเภทที่พัก ว่าคนนิยมจองแบบไหนในช่วงที่ดึงมา
9. สถานที่
"""

!pip install -q selenium

from bs4 import BeautifulSoup
import requests
import pandas as pd

import selenium
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys

from selenium import webdriver
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

"""data = [{Name:"",Type:"",PRICE:"",REVIEW:{[Name:"",information]}}  ]

Airbnb Function    (จำนวนต่อชนิต,ต้องการกี่ชนิก)
"""

import pandas as pd


type_size =12
count=12

link = []

driver = webdriver.Chrome(options=chrome_options)
driver.get("https://www.airbnb.com/?enable_auto_translate=false")
tabs = driver.find_element(By.CLASS_NAME,"c14whb16")
wait = WebDriverWait(driver, 15)
wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'ti7yjx')))
tab = tabs.find_elements(By.CLASS_NAME,"ti7yjx")

def link_get(type,size):
  wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'bn2bl2p')))
  datas = driver.find_elements(By.CLASS_NAME,"bn2bl2p")
  current_url = driver.current_url

  for i in datas[:size]:
    try:
       link_url = i.get_attribute('href')
       link.append({"type":type,"link":link_url})
    except:
      print("ERR")


for i in tab[:type_size]:
  name = i.text
  try:
    i.click()

  finally:
    try:
      link_get(name,count)
    except:
      pass
driver.quit()

data = []


for type_n in link[:101]:
      try:
        driver = webdriver.Chrome(options=chrome_options)
        url = type_n['link']
        driver.get(url)
        wait = WebDriverWait(driver, 10)
        print(driver.current_url)
        review = []
        home_name=""
        price=""
        try:
          wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'hpipapi')))
          wait.until(EC.presence_of_element_located((By.CLASS_NAME, '_1jo4hgw')))
          home_name = soup.find("h1",class_ = "hpipapi")
          home_name = home_name.text
          price = soup.find("div",class_ = "_1jo4hgw")
          price = price.text.replace('\xa0', '')
        except:
          pass



        try:
          wait.until(EC.presence_of_element_located((By.CLASS_NAME, '_162hp8xh')))
          def re ():
            data = []
            try:
              for res in soup.find_all("div",class_ = "_162hp8xh"):
                name_r = res.find_next("h3",class_="hpipapi")
                opinion = res.find_next("span",class_="ll4r2nl")
                data.append({"name":name_r.text,"opinion":opinion.text});
            except:
              pass
            finally:
              return data
          review = re()
        except:
          pass
        soup = BeautifulSoup(driver.page_source, 'lxml')


        score_r = ""
        score_c = ""

        try:
          wait.until(EC.presence_of_element_located((By.CLASS_NAME, 't1f90fvr')))


          score_c = soup.find("span",class_ = "t1f90fvr")
          splits = score_c.text.rsplit(' ',2)
          splits_2 = score_c.text.split(' ',1)

          score_c =splits[-2]
          score_r = splits_2[0]
        except:
          pass
        detail= ""
        try:
          wait.until(EC.presence_of_element_located((By.CLASS_NAME, '_tqmy57')))
          detail = soup.find("div",class_ = "_tqmy57")
          detail= detail.text
        except:
          pass
      finally:
        data.append({"Name":home_name,"Type":type_n['type'],"Price":price,"Review_Score":score_r,"Review_Count":score_c,"Detail":detail,"Reviews":review,})
        driver.quit()

import numpy as np
df = pd.DataFrame(data)

df.replace('', np.nan, inplace=True)

"""1. ชื่อที่พัก c
2. ประเภทที่พัก c
3. รายละเอียดที่พัก c
4. ราคาต่อคืน c
5. คะแนนที่ได้ c
6. จำนวนรีวิว c
7. <font color="red"> รีวิวล่าสุด 10-20 รีวิว c </font>  มากสุด 6



8. กราฟ แบ่งตามประเภทที่พัก ว่าคนนิยมจองแบบไหนในช่วงที่ดึงมา
9. สถานที่
"""

df

df['Reviews']

for index,d  in enumerate(df['Reviews'][:5]):

  if len(d) != 0:
    print("\n         "+df['Name'][index])
    for y in d:
      print("เจ้าของรีวิว:{0}   \n{1}\n".format(y['name'],y['opinion']))

import matplotlib.pyplot as plt

import seaborn as sns

value_counts = df['Type'].value_counts()

"""จำวน Type ใน Data ทั้งหมด"""

# พล็อตกราฟแบ่งตาทแนวนอน
sns.barplot(x=value_counts.values, y=value_counts.index)

# ปรับแต่งหัวข้อแกน x และ y
plt.xlabel('Count')
plt.ylabel('Type')

# แสดงกราฟ
plt.show()

"""จำนวน Revie_Count ทั้งหมดที่มีการ Review แต่ล่ะ Type"""

import re
df.replace('', np.nan, inplace=True)
df.replace(' ', np.nan, inplace=True)
df.replace('review1', np.nan, inplace=True)
df.replace('reviews2', np.nan, inplace=True)
df['Review_Count'] = pd.to_numeric(df['Review_Count'], errors='coerce')

df_re = df.dropna()
try:

  df_re['Review_Count'] = df_re[' '].str.rstrip('(')

except:
  pass

df_re['Review_Count'] = df_re['Review_Count'].astype(int)
result = df_re.groupby('Type')['Review_Count'].sum().reset_index()

result

# พล็อตกราฟแบ่งตาทแนวนอน
sns.barplot(y=result.Type, x=result.Review_Count)

# ปรับแต่งหัวข้อแกน x และ y
plt.xlabel('Count')
plt.ylabel('Type')

# แสดงกราฟ
plt.show()

print(result)

df.to_csv("stays.csv")
df_re.to_csv("clean_stays.csv")